# Base playbook sets up a Kubernetes cluster using kubeadm and kine.
# This playbook is idempotent, so it can be used on existing clusters to add new nodes, or sync their state.
# This playbook deploys a multi-node setup. It is written with a future HA deployment in mind, but for now it assumes
# a single CP node.

# The following values are hadrcoded across the playbook:
# - 10.0.0.8 as the api-server IP
# - 10.0.0.9 as the kine (etcd) IP
# Mainly because Ctrl-F is faster than what it would take me to use variables.
# Maybe in the future these IPs will be load-balanced for HA. For now, they are just extra addresses in the CP node.

- name: Common node configuration
  hosts: control-plane:workers
  remote_user: root
  strategy: free
  tasks:
    - name: Core packages are installed
      community.general.pacman:
        # https://unix.stackexchange.com/questions/274727/how-to-force-pacman-to-answer-yes-to-all-questions/584001#584001
        extra_args: --ask 4 --noconfirm
        state: present
        name: [
          # Container runtime
          cri-o, crictl, crun,
          # Kubelet & kubectl
          kubelet, kubectl,
          # Kubeadm is needed in worker nodes as it provides /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
          kubeadm,
          # NFS
          nfs-utils,
          # Misc node administration tools.
          btop, htop, lsof, nano
        ]

    - name: Copy folder structure
      ansible.builtin.file:
        path: "/{{ item.path }}"
        state: directory
        recurse: yes
      with_community.general.filetree: "{{ playbook_dir }}/files/"
      loop_control:
        label: "/{{ item.path }}"
      when: item.state == 'directory'
    - name: Copy and render template files
      ansible.builtin.template:
        src: "{{ item.src }}"
        dest: "/{{ item.path | regex_replace('\\.jinja2$', '') }}"
      with_community.general.filetree: "{{ playbook_dir }}/files/"
      loop_control:
        label: "/{{ item.path | regex_replace('\\.jinja2$', '') }}"
      when: item.state == 'file' and item.path is regex('\\.jinja2$')
    - name: Copy static files
      ansible.builtin.copy:
        src: "{{ item.src }}"
        dest: "/{{ item.path }}"
      with_community.general.filetree: "{{ playbook_dir }}/files/"
      loop_control:
        label: "/{{ item.path }}"
      when: item.state == 'file' and item.path is not regex('\\.jinja2$')

    # Kubelets are configured to _not_ use systemd-resolved.
    - name: Systemd-resolved is disabled
      ansible.builtin.systemd:
        name: systemd-resolved
        state: stopped
        enabled: false
        masked: true

    - name: CRI-O is started and enabled
      ansible.builtin.systemd:
        name: crio
        state: started
        enabled: yes
    - name: Kubelet is enabled  # Storage nodes override kubelet.service's WantedBy.
      ansible.builtin.systemd:
        name: crio
        enabled: yes

- name: Control plane node configuration
  hosts: control-plane
  remote_user: root
  tasks:
    - name: Copy files
      ansible.builtin.copy:
        src: files-controlplane/
        dest: /
    - name: CP-specific packages are installed
      community.general.pacman:
        name: [ k9s ]
        state: present

- name: Control plane is set up
  hosts: control-plane
  remote_user: root
  tasks:
    - name: Check for existing cluster
      register: admin_conf
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
    - meta: end_host
      when: admin_conf.stat.exists

    # We are not using kubeadm-managed etcd, but we can get advantage of it to generate certificates.
    - name: Create config file for generating etcd certs
      ansible.builtin.copy:
        dest: /tmp/kubeadm-etcd-certs.yaml
        content: |
          apiVersion: kubeadm.k8s.io/v1beta3
          kind: ClusterConfiguration
          etcd:
            local:
              serverCertSANs:
                - 10.0.0.9
    - name: Generate etcd certificates
      ansible.builtin.shell:
        cmd: >-
          kubeadm init --config /tmp/kubeadm-etcd-certs.yaml phase certs etcd-ca
          && kubeadm init --config /tmp/kubeadm-etcd-certs.yaml phase certs etcd-server
          && kubeadm init --config /tmp/kubeadm-etcd-certs.yaml phase certs apiserver-etcd-client

    - name: Initialize control plane node
      ansible.builtin.command:
        cmd: kubeadm init --config /etc/kubernetes/kubeadm.yaml

- name: Worker nodes are set up
  hosts: workers
  remote_user: root
  tasks:
    - name: Check for existing cluster
      register: kubelet_conf
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
    - meta: end_host
      when: kubelet_conf.stat.exists

    - name: Generate token for node
      register: kubeadm_token
      delegate_to: control-plane
      ansible.builtin.command:
        cmd: kubeadm token create
    - name: Get certificate hash
      register: kube_ca_hash
      delegate_to: control-plane
      ansible.builtin.shell:
        cmd: >-
          openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt
          | openssl rsa -pubin -outform der 2>/dev/null
          | openssl dgst -sha256 -hex
          | sed 's/^.* //'
    - name: Join node
      ansible.builtin.command:
        cmd: >-
          kubeadm join
          --config /etc/kubernetes/kubeadm.yaml
          --token={{ kubeadm_token.stdout }}
          https://10.0.0.8:6443
          --discovery-token-ca-cert-hash=sha256:{{ kube_ca_hash.stdout }}

- name: Storage NFS setup
  hosts: storage
  remote_user: root
  strategy: free
  tasks:
    - name: Configure NFS exports
      ansible.builtin.copy:
        content: |
          # Legacy HASS mount
          /mnt/zmir/docker/homeassistant	10.0.0.0/26(rw,async,no_root_squash) 127.0.0.1(rw,async,no_root_squash)
          # NFS provisioner
          /mnt/zmir/k8s  10.0.0.0/26(rw,async,no_root_squash) 127.0.0.1(rw,async,no_root_squash)
          # Media
          /mnt/zmir/media  10.0.0.0/26(rw,async,no_root_squash) 127.0.0.1(rw,async,no_root_squash)
        dest: /etc/exports.d/kubernetes.exports
    - name: Enable NFS server
      ansible.builtin.systemd:
        name: nfs-server
        state: restarted
        enabled: yes  # NFS unit has an overridden WantedBy on Terabox.
